{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b641470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1c8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Test Spark\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0adf0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70947e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-HF2TGGL.Home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fe7f95f790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2fd604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark3\\python\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58b0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_cols = [\"{}\".format(x) for x in range(2,32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5a5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb29472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae7b6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                                                                                                                        |\n",
      "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[31.0,18.02,27.6,117.5,1013.0,0.09489,0.1036,0.1086,0.07055,0.1865,0.06333,0.6249,1.89,3.972,71.55,0.004433,0.01421,0.03233,0.009854,0.01694,0.003495,21.63,37.08,139.7,1436.0,0.1195,0.1926,0.314,0.117,0.2677,0.08113,5.0,5.0]|\n",
      "+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "letter_recognition_df = sqlcontext.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true').load('wpbc.csv')\n",
    "feature_columns = ['Time','Mean Radius','Mean Texture','Mean Perimeter','Mean Area','Mean Smoothness','Mean Compactness','Mean Concavity','Mean Concave Points','Mean Symmetry','Mean Fractal Dimension','Radius SE','Texture SE','Perimeter SE','SE Area','SE Smoothness','SE Compactness','SE Concavity','SE Concave Points','SE Symmetry','SE Fractal Dimension','Worst Radius','Worst Texture','Worst Perimeter','Worst Area','Worst Smoothness','Worst Compactness','Worst Concavity','Worst Concave Points','Worst Symmetry','Worst Fractal Dimension','Tumor size','Lymph node status']\n",
    "#feature_columns = ['Mean Radius','Mean Texture','Mean Perimeter']\n",
    "vector_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'features')\n",
    "vectorised_df = vector_assembler.transform(letter_recognition_df).withColumnRenamed('Outcome', 'label').select('label', 'features')\n",
    "vectorised_df.show(1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0303f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#letter_recognition_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "808057d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withMean=True, withStd=True)\n",
    "#scaler = StandardScaler(inputCol='features', outputCol='features', withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(vectorised_df)\n",
    "vectorised_df = scaler_model.transform(vectorised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea853a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorised_df = vectorised_df.select(\"scaledFeatures\",\"label\")\n",
    "vectorised_df = vectorised_df.withColumnRenamed(\"scaledFeatures\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8438aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorised_df.write.mode(\"overwrite\").csv(\"wdbc_normalized.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d12806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 27)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = vectorised_df.randomSplit([0.8, 0.2], seed=12345)\n",
    "train_df.count(), test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcd3ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dffced83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import VectorAssembler\n",
    "#feature_columns = ['Mean Radius','Mean Texture','Mean Perimeter']\n",
    "#assembler = VectorAssembler(inputCols = feature_columns, outputCol='features')\n",
    "#vectorised_df = assembler.transform(train_df).withColumnRenamed('Outcome', 'label').select('label', 'features')\n",
    "#train_df = assembler.transform(train_df)\n",
    "#test_df = assembler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dc40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae35d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[-1.3306283967537...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48bdb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [train_df.schema['features'].metadata['ml_attr']['num_attrs'], 128, 64, 32, 16 , 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e74cc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MultilayerPerceptronClassifier(layers=layers, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "604b7d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c543c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \n",
      "+-----+--------------------+--------------------+----------+\n",
      "|label|            features|         probability|prediction|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "|    0|[-1.2726970886365...|[0.99999999994896...|       0.0|\n",
      "|    1|[-1.0989031642849...|[1.79426719706482...|       1.0|\n",
      "|    1|[-1.0989031642849...|[0.99999999996569...|       0.0|\n",
      "|    1|[-1.0699375102263...|[0.28493391318038...|       1.0|\n",
      "|    1|[-1.0409718561677...|[1.85770919155627...|       1.0|\n",
      "|    1|[-0.9540748939919...|[0.99877739773863...|       0.0|\n",
      "|    0|[-0.9251092399333...|[0.99999999988153...|       0.0|\n",
      "|    1|[-0.6064870452887...|[1.36717813813749...|       1.0|\n",
      "|    0|[-0.2588991965856...|[2.04538004831459...|       1.0|\n",
      "|    1|[-0.2299335425270...|[0.99999988151933...|       0.0|\n",
      "|    1|[-0.2009678884684...|[0.99999999994181...|       0.0|\n",
      "|    0|[0.17558561429335...|[0.99999999991079...|       0.0|\n",
      "|    0|[0.26248257646914...|[0.99999999989814...|       0.0|\n",
      "|    0|[0.29144823052774...|[0.99999999855055...|       0.0|\n",
      "|    1|[0.32041388458634...|[0.99999999986317...|       0.0|\n",
      "|    0|[0.34937953864494...|[0.99999999556606...|       0.0|\n",
      "|    0|[0.40731084676213...|[0.99999999993252...|       0.0|\n",
      "|    0|[0.43627650082073...|[0.99999999991933...|       0.0|\n",
      "|    0|[0.49420780893792...|[0.99999999997285...|       0.0|\n",
      "|    0|[0.52317346299652...|[0.99999999984452...|       0.0|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_df = model.transform(test_df)\n",
    "print(\"TEST DATASET PREDICTIONS AGAINST ACTUAL LABEL: \")\n",
    "test_predictions_df.select(\"label\", \"features\", \"probability\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f33c9883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Dataset = 0.777778\n",
      "Precision on Test Dataset = 0.781818\n",
      "Recall on Test Dataset = 0.777778\n"
     ]
    }
   ],
   "source": [
    "prediction_and_labels = test_predictions_df.select(\"prediction\", \"label\")\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(metricName=\"weightedRecall\")\n",
    "print(\"Accuracy on Test Dataset = %g\" % accuracy_evaluator.evaluate(prediction_and_labels))\n",
    "print(\"Precision on Test Dataset = %g\" % precision_evaluator.evaluate(prediction_and_labels))\n",
    "print(\"Recall on Test Dataset = %g\" % recall_evaluator.evaluate(prediction_and_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676fc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dae75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f03af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370f614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493df341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab08b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3eccad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29a233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1796a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec277b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc1693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7b375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc81fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e88f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae22eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2240feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611305f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5086e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
